# -*- coding: utf-8 -*-
"""Digital Sociology - Gruppo 15 - Presentazione.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_N5XrUWtJ95Jg-GD32mEqLZzRhwSzDVn
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import time
import seaborn as sns
import chardet
import math
import matplotlib.patches as mpatches
from datetime import datetime
import re
from collections import Counter
import folium
from geopy.geocoders import Nominatim
from collections import defaultdict
import json

"""# ðŸ“Š **Organizzazione e pulizia dei dati**"""

df_basta_immigrazione = pd.read_excel('/content/basta_immigrazione_dataset_v3.xlsx')
df_basta_immigrazione.head()

df_stop_immigrazione = pd.read_excel('/content/stop_immigrazione_dataset_v2.xlsx')
df_stop_immigrazione.head()

print("Informazioni su df_stop_immigrazione:")
print(df_stop_immigrazione.info())

print("\nInformazioni su df_basta_immigrazione:")
print(df_basta_immigrazione.info())

df_stop_immigrazione = df_stop_immigrazione.rename(columns={'data/legacy/created_at': 'created_at'})
print(df_stop_immigrazione)

df_basta_immigrazione = df_basta_immigrazione.rename(columns={'data/legacy/favorite_count':'favorite_count', 'user_screen_name': 'screen_name', 'professional/professional_type': 'professional_type'})
print(df_basta_immigrazione)

df_stop_immigrazione = df_stop_immigrazione.rename(columns={'data/core/user_results/result/legacy/location': 'user_location', 'data/legacy/favorite_count': 'favourite_count'})
print(df_stop_immigrazione)

df_stop_immigrazione = df_stop_immigrazione.drop(columns=['bookmark_count', 'data/views/count', 'professional/category/name'])

df_basta_immigrazione = df_basta_immigrazione.drop(columns=['data/legacy/reply_count.1', 'data/legacy/is_quote_status', 'default_profile_image', 'display_url', 'hashtags/1/text', 'default_profile_image', 'user_description', 'data/legacy/retweet_count', 'tipo_account'])

print("Informazioni su df_stop_immigrazione:")
print(df_stop_immigrazione.info())

print("\nInformazioni su df_basta_immigrazione:")
print(df_basta_immigrazione.info())

df_immigrazione = pd.concat([df_stop_immigrazione, df_basta_immigrazione], axis=0)
print(df_immigrazione)

"""# ðŸ“Š **Analisi generali dei tweets**

## ðŸ“… **Data di pubblicazione**
"""

df_immigrazione['created_at'] = pd.to_datetime(df_immigrazione['created_at'], format='%a %b %d %H:%M:%S +0000 %Y')
df_immigrazione['year'] = df_immigrazione['created_at'].dt.year
df_immigrazione['month'] = df_immigrazione['created_at'].dt.month
print(df_immigrazione[['year', 'month']])

df_immigrazione['created_at'] = pd.to_datetime(df_immigrazione['created_at'], format='%a %b %d %H:%M:%S +0000 %Y')

df_immigrazione['year'] = df_immigrazione['created_at'].dt.year

year_counts = df_immigrazione.groupby(['year']).size().reset_index(name='count')

print(year_counts)

year_counts = df_immigrazione['year'].value_counts().sort_index()

plt.figure(figsize=(10, 6))
year_counts.plot(kind='bar', color= '#08a895')
plt.xlabel('Anni')
plt.ylabel('Frequenza')
plt.title('Frequenza degli anni')
plt.xticks(rotation=0)
plt.show()

"""## **Nueva secciÃ³n**

## **Lingue**
"""

lingue_counts = df_immigrazione['data/legacy/lang'].value_counts()
print(lingue_counts)

plt.figure(figsize=(12, 8))
lingue_counts.plot(kind='bar', color='orange')
plt.title('Lingue piÃ¹ utilizzati nei tweets')
plt.xlabel('Lingua')
plt.ylabel('Frequenza')
plt.xticks(rotation=45, ha='right')
plt.show()

"""### ðŸ’¡ **Insight: "qme" e "qht"**"""

condiciones_filtro = (df_immigrazione['data/legacy/lang'] == 'qme') & (df_immigrazione['data/legacy/lang'] != 'qht')
df_filtrado_hashtags = df_immigrazione[condiciones_filtro]
pd.set_option('display.max_colwidth', None)
print(df_filtrado_hashtags['data/legacy/full_text'])

import re

def extract_hashtags(tweet):
    return re.findall(r'#\w+', tweet)


df_filtrado_hashtags['hashtags'] = df_filtrado_hashtags['data/legacy/full_text'].apply(extract_hashtags)


print(df_filtrado_hashtags[['hashtags']])

from collections import Counter

all_hashtags = [hashtag for hashtags in df_filtrado_hashtags['hashtags'] for hashtag in hashtags]
hashtag_counts = Counter(all_hashtags)


print(hashtag_counts)

from wordcloud import WordCloud
import matplotlib.pyplot as plt

wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(hashtag_counts)

plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.show()

"""## **Menzioni**"""

data = df_immigrazione['data/legacy/full_text']
df = pd.DataFrame(data)

# Funzione per raccogliere i menzioni di ogni tweet (nel caso di che ci siano)
def extract_mentions(tweet):
    mentions = re.findall(r'@\w+', tweet)
    return mentions

df_immigrazione['mentions'] = df_immigrazione['data/legacy/full_text'].apply(extract_mentions)

all_mentions = [mention for mentions_list in df_immigrazione['mentions'] for mention in mentions_list]

mention_counts = Counter(all_mentions)

mentions_df = pd.DataFrame(mention_counts.items(), columns=['MenciÃ³n', 'Frecuencia']).sort_values(by='Frecuencia', ascending=False)
print(mentions_df)

mentions_to_plot = mentions_df[mentions_df['Frecuencia'] >= 10]

print(mentions_to_plot)

plt.figure(figsize=(10, 6))
sns.barplot(data=mentions_to_plot, x='MenciÃ³n', y='Frecuencia', palette='plasma')
plt.title('Tutte le menzioni ')
plt.xlabel('Menzioni')
plt.ylabel('Frequenza')
plt.xticks(rotation=45)
plt.show()

"""## **Hashtags piÃ¹ frequenti**"""

columnas_hashtags = df_immigrazione[['hashtags/0/text']]

hashtags_series = columnas_hashtags.stack()

hashtags_df = hashtags_series.reset_index(drop=True)

frecuencia_hashtags = hashtags_df.value_counts()

print(frecuencia_hashtags)

wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(frecuencia_hashtags)

plt.figure(figsize=(10, 6))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.show()

"""# ðŸ“Š **Analisi di variabili specifici: fonti, account verificati, fake account e costruzioni pronominali**"""

conteo_tipos_fonti = df_immigrazione['expanded_url'].value_counts()
print(conteo_tipos_fonti)

palabras_interes = [r'\bblogpot\b|\bwordpress\b', r'\bfacebook\b|\binstagram\b|\btwitter\b',r'\b.eu\b|\b.org\b|\b.gov\b|\b.it\b']
ocurrencias = {palabra: df_immigrazione['expanded_url'].str.contains(palabra, na=False).sum() for palabra in palabras_interes}
labels_palabras = list(ocurrencias.keys())
sizes_palabras = list(ocurrencias.values())
colors = ['pink', 'lightgreen', 'lightblue']

plt.figure(figsize=(8, 8))
plt.pie(sizes_palabras, labels=labels_palabras, autopct='%1.1f%%', colors = colors, startangle=140)
plt.title('Fonti piÃ¹ utilizzati')
plt.axis('equal')
plt.show()

conteo_tipos_fonti = df_immigrazione['expanded_url'].value_counts()
print(conteo_tipos_fonti)

conteo_tipos_fonti = df_immigrazione['expanded_url'].value_counts()
pattern = r'\bblogpot\b|\bwordpress\b'
fonti_blogs = df_immigrazione.loc[df_immigrazione['expanded_url'].str.contains(pattern, case=False, na=False)]
pd.set_option('display.max_colwidth', None)
print(fonti_blogs['data/legacy/full_text'])

conteo_tipos_fonti = df_immigrazione['expanded_url'].value_counts()
pattern = r'\bfacebook\b|\binstagram\b'
fonti_reti_sociali = df_immigrazione.loc[df_immigrazione['expanded_url'].str.contains(pattern, case=False, na=False)]
pd.set_option('display.max_colwidth', None)
print(fonti_reti_sociali['data/legacy/full_text'])

conteo_tipos_fonti = df_immigrazione['expanded_url'].value_counts()
pattern = r'\b.eu\b|\b.org\b|\b.gov\b|\b.it\b'
fonti_siti_ufficiali = df_immigrazione.loc[df_immigrazione['expanded_url'].str.contains(pattern, case=False, na=False)]
pd.set_option('display.max_colwidth', None)
print(fonti_blogs['data/legacy/full_text'])

"""## ðŸ”µ **Account verificati**"""

df_immigrazione_longitud= len(df_immigrazione)
conteo_true = df_immigrazione['is_blue_verified'].sum()
conteo_false = len(df_immigrazione) - conteo_true

print("Totale account verificati':", conteo_true)
print("Totale account non verificati:", conteo_false)

sizes_df_immigrazione = [conteo_true, conteo_false]
colors = ['lightblue','lightcoral']
labels = ['Account verificati', 'Account non verificati']
plt.figure(figsize=(6, 6))
plt.pie(sizes_df_immigrazione, colors=colors, autopct='%1.1f%%', startangle=140)
plt.title('Percentuale di account verificati e non verificati')
plt.axis('equal')
plt.show()

palabras_a_excluir = ['OpenAI', 'Ordina', 'Risparmia', '%', 'potenziale illimitato']
condiciones_filtro = (df_immigrazione['is_blue_verified'] == True) & (df_immigrazione['data/legacy/lang'] == 'it') & ~df_immigrazione['data/legacy/full_text'].str.contains('|'.join(palabras_a_excluir))
df_filtrado = df_immigrazione[condiciones_filtro]
pd.set_option('display.max_colwidth', None)
print(df_filtrado['data/legacy/full_text'])

"""## ðŸ“¢ **Maggiore quantitÃ  di risposte**"""

df_risposte = df_immigrazione.sort_values(by='data/legacy/reply_count', ascending=False)
df_seleccionado = df_risposte[['screen_name', 'data/legacy/reply_count']]
print(df_seleccionado)

df_risposte = df_immigrazione.sort_values(by='data/legacy/reply_count', ascending=False)
df_seleccionado = df_risposte[['screen_name', 'data/legacy/reply_count', 'data/legacy/full_text']]
print(df_seleccionado)

"""## ðŸš« **Filtro per "dettetare" possibile** ***fake accounts***"""

#Mettiamo delle condizione come che non sia un'account verificato, che abbia il profile in modo 'default' e che abbia una quantitÃ  minore di 10 follower
condiciones_filtro = (df_immigrazione['is_blue_verified'] == False) & (df_immigrazione['default_profile'] == True) & (df_immigrazione['followers_count'] < 10)
df_filtrado = df_immigrazione[condiciones_filtro]
pd.set_option('display.max_colwidth', None) #Questo ci permette di vedere il tweet compieto nella consola
print(df_filtrado['data/legacy/full_text'])

"""## ðŸ§‘ðŸ§‘ **Costruzione discorsiva tramite pronomi: "noi" e "loro"**

### **Costruzione del "noi"**
"""

immigrazione_noi = df_immigrazione.loc[df_immigrazione['data/legacy/full_text'].str.contains(r'\bnoi\b', case=False, na=False)]
print(immigrazione_noi['data/legacy/full_text'])

immigrazione_noi = df_basta_immigrazione.loc[df_basta_immigrazione['data/legacy/full_text'].str.contains(r'\babbiamo\b', case=False, na=False)]
print(immigrazione_noi['data/legacy/full_text'])

immigrazione_noi = df_basta_immigrazione.loc[df_basta_immigrazione['data/legacy/full_text'].str.contains(r'\bsiamo\b', case=False, na=False)]
print(immigrazione_noi['data/legacy/full_text'])

immigrazione_noi = df_immigrazione.loc[df_immigrazione['data/legacy/full_text'].str.contains(r'\b\w+amo\b', case=False, na=False)]
print(immigrazione_noi['data/legacy/full_text'])

"""### **Costruzione del "loro"**"""

immigrazione_loro = df_immigrazione.loc[df_immigrazione['data/legacy/full_text'].str.contains(r'\bloro\b', case=False, na=False)]
print(immigrazione_loro['data/legacy/full_text'])

immigrazione_loro = df_immigrazione.loc[df_immigrazione['data/legacy/full_text'].str.contains(r'\bhanno\b', case=False, na=False)]
print(immigrazione_loro['data/legacy/full_text'])

immigrazione_loro = df_immigrazione.loc[df_immigrazione['data/legacy/full_text'].str.contains(r'\bsono\b', case=False, na=False)]
print(immigrazione_loro['data/legacy/full_text']) #Atenzione per che questo sono puÃ² essere anche prima persona !!! #italianproblems

immigrazione_loro = df_immigrazione.loc[df_immigrazione['data/legacy/full_text'].str.contains(r'\b\w+ano\b', case=False, na=False)]
print(immigrazione_loro['data/legacy/full_text'])